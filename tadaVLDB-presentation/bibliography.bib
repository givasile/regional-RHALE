@book{molnar2022,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}

@article{Apley2020,
annote = {The paper that proposed ALE plots.},
archivePrefix = {arXiv},
arxivId = {1612.08468},
author = {Apley, Daniel W. and Zhu, Jingyu},
doi = {10.1111/rssb.12377},
eprint = {1612.08468},
file = {:home/givasile/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Apley, Zhu - 2020 - Visualizing the effects of predictor variables in black box supervised learning models.pdf:pdf},
issn = {14679868},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Functional analysis of variance,Marginal plots,Partial dependence plots,Supervised learning,Visualization},
mendeley-groups = {ΧΑΙ,Feature Effect paper},
number = {4},
pages = {1059--1086},
title = {{Visualizing the effects of predictor variables in black box supervised learning models}},
volume = {82},
year = {2020}
}



@article{BikeSharing,
year={2013},
issn={2192-6352},
journal={Progress in Artificial Intelligence},
doi={10.1007/s13748-013-0040-3},
title={Event labeling combining ensemble detectors and background knowledge},
url={[Web Link]},
publisher={Springer Berlin Heidelberg},
keywords={Event labeling; Event detection; Ensemble learning; Background knowledge},
author={Fanaee-T, Hadi and Gama, Joao},
pages={1-15}
}


@article{Friedman2001,
abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization iti function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent "boosting" paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such "TreeBoost" models are presented. Gradient boosting of regression trees produces competitives highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
author = {Friedman, Jerome H.},
doi = {10.1214/aos/1013203451},
file = {:home/givasile/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedman - 2001 - Greedy function approximation A gradient boosting machine.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Boosting,Decision trees,Function estimation,Robust nonparametric regression},
mendeley-groups = {Feature Effect paper},
month = {oct},
number = {5},
pages = {1189--1232},
publisher = {Institute of Mathematical Statistics},
title = {{Greedy function approximation: A gradient boosting machine}},
volume = {29},
year = {2001}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{gkolemis22a,
  title = {DALE: Differential Accumulated Local Effects for efficient and accurate global explanations},
  booktitle = {Asian Conference on Machine Learning (ACML)},
  author = {Gkolemis, Vasilis and Dalamagas, Theodore and Diou, Christos},
  keywords = {Feature Effect, Explainable AI, Interpretable ML, Global Methods, Neural Networks},
  year = {2022},
  month = oct,
  journal = {Proceedings of Machine Learning Research},
}

@incollection{gkolemis2023rhale,
  title={RHALE: Robust and Heterogeneity-Aware Accumulated Local Effects},
  author={Gkolemis, Vasilis and Dalamagas, Theodore and Ntoutsi, Eirini and Diou, Christos},
  booktitle={ECAI 2023},
  pages={859--866},
  year={2023},
  publisher={IOS Press}
}

@article{friedman_predictive_2008,
  title = {Predictive learning via rule ensembles},
  journal = {The annals of applied statistics},
  author = {Friedman, Jerome H and Popescu, Bogdan E},
  year = {2008},
  note = {Publisher: JSTOR},
  pages = {916--954},
}

@misc{goldstein_peeking_2014,
  title = {Peeking {Inside} the {Black} {Box}: {Visualizing} {Statistical} {Learning} with {Plots} of {Individual} {Conditional} {Expectation}},
  shorttitle = {Peeking {Inside} the {Black} {Box}},
  url = {http://arxiv.org/abs/1309.6392},
  language = {en},
  urldate = {2023-01-23},
  publisher = {arXiv},
  author = {Goldstein, Alex and Kapelner, Adam and Bleich, Justin and Pitkin, Emil},
  month = mar,
  year = {2014},
  note = {arXiv:1309.6392 [stat]},
  keywords = {Statistics - Applications},
  annote = {Comment: 22 pages, 14 figures, 2 algorithms},
  file = {Goldstein et al. - 2014 - Peeking Inside the Black Box Visualizing Statisti.pdf:/home/givasile/Zotero/storage/PIDL7JCQ/Goldstein et al. - 2014 - Peeking Inside the Black Box Visualizing Statisti.pdf:application/pdf},
}


@misc{herbinger_repid_2022,
  title = {{REPID}: {Regional} {Effect} {Plots} with implicit {Interaction} {Detection}},
  shorttitle = {{REPID}},
  url = {http://arxiv.org/abs/2202.07254},
  doi = {10.48550/arXiv.2202.07254},
  abstract = {Machine learning models can automatically learn complex relationships, such as non-linear and interaction effects. Interpretable machine learning methods such as partial dependence plots visualize marginal feature effects but may lead to misleading interpretations when feature interactions are present. Hence, employing additional methods that can detect and measure the strength of interactions is paramount to better understand the inner workings of machine learning models. We demonstrate several drawbacks of existing global interaction detection approaches, characterize them theoretically, and evaluate them empirically. Furthermore, we introduce regional effect plots with implicit interaction detection, a novel framework to detect interactions between a feature of interest and other features. The framework also quantifies the strength of interactions and provides interpretable and distinct regions in which feature effects can be interpreted more reliably, as they are less confounded by interactions. We prove the theoretical eligibility of our method and show its applicability on various simulation and real-world examples.},
  urldate = {2023-06-11},
  publisher = {arXiv},
  author = {Herbinger, Julia and Bischl, Bernd and Casalicchio, Giuseppe},
  month = feb,
  year = {2022},
  note = {arXiv:2202.07254 [cs, stat]},
  keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
  file = {arXiv Fulltext PDF:/home/givasile/Zotero/storage/2JJX3RV3/Herbinger et al. - 2022 - REPID Regional Effect Plots with implicit Interac.pdf:application/pdf;arXiv.org Snapshot:/home/givasile/Zotero/storage/4WSISA6V/2202.html:text/html},
}

@article{herbinger2023decomposing,
  title={Decomposing Global Feature Effects Based on Feature Interactions},
  author={Herbinger, Julia and Bischl, Bernd and Casalicchio, Giuseppe},
  journal={arXiv preprint arXiv:2306.00541},
  year=2023
}


@article{gkolemis2023regionally,
  title={Regionally Additive Models: Explainable-by-design models minimizing feature interactions},
  author={Gkolemis, Vasilis and Tzerefos, Anargiros and Dalamagas, Theodore and Ntoutsi, Eirini and Diou, Christos},
  journal={arXiv preprint arXiv:2309.12215},
  year={2023}
}